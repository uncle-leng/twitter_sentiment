{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import draft\n",
    "\n",
    "# users = draft.get_most_location_id(10)\n",
    "\n",
    "# get top users\n",
    "# users = draft.get_top_n_user(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @olivercrocker: Great pulling power from the mighty Eric Richard (Sgt. Bob Cryer) so far on this #BankHolidayWeekend #TheBill legend hasâ€¦', datetime.datetime(2018, 5, 7, 19, 51, 38), None]\n",
      "['Just posted a photo @ Pie In The Sky Roadhouse https://t.co/RYHsdnw0pq', datetime.datetime(2018, 5, 7, 5, 5, 33), {'type': 'Point', 'coordinates': [150.58197069, -33.51530863]}]\n",
      "['Allendale @ Goodnight https://t.co/wPsNNdQBwP', datetime.datetime(2018, 5, 7, 4, 52, 3), {'type': 'Point', 'coordinates': [143.332, -34.9123]}]\n",
      "['RT @Arsenal: #MerciArsÃ¨ne https://t.co/hwab7mG6XL', datetime.datetime(2018, 5, 6, 14, 9, 25), None]\n",
      "['RT @Youaremygooners: #thankful for the tireless work that he has done for our club. Looking at where we started &amp; where we are today, he haâ€¦', datetime.datetime(2018, 5, 6, 14, 8, 37), None]\n",
      "['RT @BlogtorWho: Video of the Day â€“ Doctor Who -The Silurians,\\xa01970 https://t.co/FRxz75h1Wy https://t.co/n0QB8gLXRp', datetime.datetime(2018, 5, 6, 14, 7, 36), None]\n",
      "['RT @missydepino: @Starbucks The police were called because these men hadnâ€™t ordered anything. They were waiting for a friend to show up, whâ€¦', datetime.datetime(2018, 5, 6, 14, 6, 46), None]\n",
      "['RT @MistyMoonEvents: This May two British institutions are coming to Misty Moon a window cleaner &amp; The Old Bill. On the 12/05 The Bill Reunâ€¦', datetime.datetime(2018, 5, 6, 14, 4, 56), None]\n",
      "['Hoping for a speedy recovery, Sir Alex. https://t.co/3ktGlLjD6P', datetime.datetime(2018, 5, 6, 14, 1, 59), None]\n",
      "['Just posted a photo https://t.co/VBs38I4hPJ', datetime.datetime(2018, 5, 6, 9, 7, 11), None]\n"
     ]
    }
   ],
   "source": [
    "import draft\n",
    "'''\n",
    "[{'key': 256478435, 'value': 2464}, \n",
    "{'key': 931566656115032000, 'value': 1211}, \n",
    "{'key': 3958911379, 'value': 1093}, \n",
    "{'key': 979984755125928000, 'value': 958}, \n",
    "{'key': 133042870, 'value': 871},  # selected user\n",
    "{'key': 971914328982011900, 'value': 823}, \n",
    "{'key': 57314631, 'value': 746}, \n",
    "{'key': 2427740995, 'value': 717}, \n",
    "{'key': 378439995, 'value': 686}, \n",
    "{'key': 347883924, 'value': 655}] # candidate user\n",
    "'''\n",
    "\n",
    "'''\n",
    "candidate tweets\n",
    "{'key': 3635899574, 'value': 86}\n",
    "{'key': 1479269839, 'value': 75}\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# get user with coordinate time and tweets\n",
    "# user1 = draft.get_tweet_location_coordinate(3635899574)\n",
    "# user2 = draft.get_tweet_location_coordinate(1479269839) # selected user -> user2\n",
    "user2 = draft.get_user_all_tweet(1479269839)\n",
    "for i in user2[:10]:\n",
    "    print(i)\n",
    "\n",
    "# user_tweets_1 = getTweets(user1)\n",
    "# user_tweets_2 = getTweets(user2)\n",
    "\n",
    "# print('-----user1-----')\n",
    "# user1_tweets = []\n",
    "# for i in user1:\n",
    "#     print(i[0])\n",
    "# print('-----user2-----')\n",
    "# for i in user2:\n",
    "#     print(i[1])\n",
    "# get user tweets\n",
    "# user_tweets_1 = draft.get_user_tweets(133042870)\n",
    "# user_tweets_2 = draft.get_user_tweets(347883924)\n",
    "# print(len(user_tweets_1))\n",
    "# print(len(user_tweets_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3202\n"
     ]
    }
   ],
   "source": [
    "# number of tweets\n",
    "print(len(user2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 115 ms, total: 26 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# topic modelling----------------\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "def getTweets(user):\n",
    "    tweet = []\n",
    "    for i in user:\n",
    "        if not i[0].startswith('RT') and not i[0].startswith('Just posted a photo'):\n",
    "            tweet.append(i[0])\n",
    "    return tweet\n",
    "\n",
    "user_tweets_2 = getTweets(user2)\n",
    "\n",
    "def getTweetsCorpus(user_tweets):\n",
    "    punctuation = set(string.punctuation)\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop.update(['I', 'Iâ€™m', 'us', 'u', 'Heâ€™s', 'We', 'And', 'You','When', 'Yeah','Thatâ€™s', 'It', 'The',\n",
    "                 'This','Its','Im', 'That', 'Oh', 'one', 'LOL', 'A', 'He','Just'])\n",
    "    punctuation.add('â€¦')\n",
    "\n",
    "    lemma = WordNetLemmatizer()\n",
    "    pattern = re.compile('(#[A-Za-z0-9]+)|(@[A-Za-z0-9]+)')\n",
    "    \n",
    "    corpus = []\n",
    "    for i in user_tweets:\n",
    "        # remove @ and # \n",
    "        tweet = re.sub(pattern,' ', i).strip()\n",
    "        # remove http...\n",
    "        tweet = [i for i in tweet.split() if not i.startswith('http')]\n",
    "    \n",
    "        # remove verb\n",
    "        pos_tag = nltk.pos_tag(tweet)\n",
    "        tweet = [i[0] for i in pos_tag if (not i[1].startswith('V')) and (i[1] != 'IN') ]\n",
    "    \n",
    "        # remove stop words\n",
    "        tweet = \" \".join([i for i in tweet if i not in stop])\n",
    "        # remove puncutation\n",
    "        tweet = ''.join([i for i in tweet if i not in punctuation])\n",
    "        # normalise the word\n",
    "        # tweet = [lemmatize(word) for word in tweet.split()]\n",
    "        # not lemmatize\n",
    "        tweet = [word for word in tweet.split()]\n",
    "    \n",
    "        corpus.append(tweet)\n",
    "        # print(tweet)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "# user1_corpus = getTweetsCorpus(user_tweets_1)\n",
    "user2_corpus = getTweetsCorpus(user_tweets_2)\n",
    "\n",
    "def getTopicsLDA(corpus):\n",
    "\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "\n",
    "    # filter the extreme tokens\n",
    "    dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
    "\n",
    "    # Converting list of corpus into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "\n",
    "    # Creating the object for LDA model using gensim library\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "    # Running and Trainign LDA model on the document term matrix.\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=7, id2word = dictionary, passes=50, dtype=np.float64)\n",
    "\n",
    "    return ldamodel\n",
    "\n",
    "# user1_topics_lda = getTopicsLDA(user1_corpus)\n",
    "user2_topics_lda = getTopicsLDA(user2_corpus)\n",
    "\n",
    "# get probability distribution for each tweet\n",
    "# probability = ldamodel.get_document_topics(doc_term_matrix)\n",
    "# print(len(probability))\n",
    "# for i in probability:\n",
    "#     print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# year = user2[0][1].year\n",
    "# month = user2[0][1].month\n",
    "# day = user2[0][1].day\n",
    "# hour = user2[0][1].hour\n",
    "# minute = user2[0][1].minute\n",
    "# print(year)\n",
    "# print(month)\n",
    "# print(day)\n",
    "# print(hour)\n",
    "# print(minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(0, '0.073*\"New\" + 0.067*\"Wales\" + 0.067*\"South\" + 0.043*\"frain\" + 0.021*\"Australia\"')\n",
      "(1, '0.021*\"Cafe\" + 0.019*\"thing\" + 0.016*\"always\" + 0.016*\"Queen\" + 0.016*\"White\"')\n",
      "(2, '0.159*\"ðŸ“·\" + 0.025*\"Awesome\" + 0.018*\"So\" + 0.013*\"Well\" + 0.012*\"awesome\"')\n",
      "(3, '0.032*\"Retreat\" + 0.032*\"Wombatz\" + 0.019*\"one\" + 0.015*\"show\" + 0.014*\"Yes\"')\n",
      "(4, '0.048*\"awesome\" + 0.036*\"sl\" + 0.022*\"work\" + 0.018*\"My\" + 0.016*\"OMG\"')\n",
      "(5, '0.055*\"ðŸ“·\" + 0.029*\"Screen\" + 0.024*\"caps\" + 0.017*\"Frain\" + 0.016*\"True\"')\n",
      "(6, '0.037*\"Happy\" + 0.028*\"ðŸ“·\" + 0.014*\"birthday\" + 0.014*\"Tudors\" + 0.013*\"James\"')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def showTopics(user_topics_lda): \n",
    "    for i in user_topics_lda.print_topics(num_words=5):\n",
    "        print(i)\n",
    "        \n",
    "\n",
    "#print(showTopics(user1_topics_lda))\n",
    "print('\\n')\n",
    "print(showTopics(user2_topics_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_key_word = ['New South Wales', \n",
    "                  'Boorowa','Cafe',\n",
    "                  'frain','Star', 'Trek',\n",
    "                  'Wombatz','Love',\n",
    "                  'Happy','photo',\n",
    "                  'James','work','Queen',\n",
    "                  'OMG','Australia','birthday']\n",
    "\n",
    "def getTweetsByKeyWord(key_word):\n",
    "    topics_sentence = {}\n",
    "    for i in user2:\n",
    "        if i[0].startswith('Just posted a photo') or i[0].startswith('RT'):\n",
    "            continue\n",
    "        time = i[1]\n",
    "        for j in key_word:\n",
    "            if j in i[0]:\n",
    "                temp = topics_sentence.get(j, set())\n",
    "                temp.add((i[0], time))\n",
    "                topics_sentence[j] = temp\n",
    "    return topics_sentence\n",
    "\n",
    "topic_sentence = getTweetsByKeyWord(topic_key_word)\n",
    "\n",
    "def getOriginalTweets(uset_topic_lad):\n",
    "    pattern = re.compile('\"')\n",
    "    topics = {}\n",
    "    # list of (int, list of (str, float))\n",
    "    for i in uset_topic_lad.print_topics(num_words=5):\n",
    "        topic = i[0]\n",
    "        key_word = i[1].split('+')\n",
    "        key_word = [re.sub(pattern,'', i.split(\"*\")[1]).strip() for i in key_word]\n",
    "        topics[topic] = set(key_word)\n",
    "\n",
    "    topics_sentence = {}\n",
    "    for i in user_tweets:\n",
    "        tweet = [word for word in i.split() if not word.startswith('http')]\n",
    "        tweet = ' '.join(tweet)\n",
    "        for k,v in topics.items():\n",
    "            for word in v:\n",
    "                if word in tweet:\n",
    "                    temp = topics_sentence.get(k, set())\n",
    "                    temp.add(tweet)\n",
    "                    topics_sentence[k] = temp\n",
    "    return topics_sentence\n",
    "\n",
    "# user1_topic = getOriginalTweets(user1_topics_lda)\n",
    "# user2_topic = getOriginalTweets(user2_topics_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('key_word_tweets.txt', 'w')\n",
    "\n",
    "for i in topic_sentence:\n",
    "    f.write('{}\\n'.format(i))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write result to a file\n",
    "def outputTopics(topic_sentence, filename):\n",
    "    f = open(filename,'w')\n",
    "    for k, v in topic_sentence.items():\n",
    "        f.write('\\n---------- Topic key word: {} ----------\\n'.format(k))\n",
    "        for i in v:\n",
    "            f.write('\\n{}, => {} \\n'.format(i[0], i[1]))\n",
    "    f.close() \n",
    "    \n",
    "# outputTopics(user1_topic, 'user1_topic.txt')\n",
    "outputTopics(topic_sentence, 'user2_topic_key_word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(4, 6): 265, (14, 16): 56, (8, 10): 366, (20, 22): 318, (12, 14): 334, (6, 8): 352, (22, 24): 570, (0, 2): 342, (2, 4): 251, (10, 12): 279, (18, 20): 80, (16, 18): 6}\n"
     ]
    }
   ],
   "source": [
    "# get tweeting time from 00:00 to 23:59 in one day\n",
    "from datetime import datetime\n",
    "\n",
    "def getTweetTime(user):\n",
    "    time = []\n",
    "    for i in user:\n",
    "        time.append(i[1])\n",
    "    return time\n",
    "\n",
    "tweet_time = getTweetTime(user2)\n",
    "\n",
    "time_format = '%a %b %d %H:%M:%S %z %Y'\n",
    "time_zone = []\n",
    "for i in range(0, 24, 2):\n",
    "    time_zone.append([i, i+2])\n",
    "\n",
    "tweet_time_dict = {}\n",
    "for i in tweet_time:\n",
    "    # time_object = datetime.strptime(i, time_format)\n",
    "    hour = i.hour\n",
    "    minute = i.minute\n",
    "    time = hour + float(minute / 60)\n",
    "    for zone in time_zone:\n",
    "        if zone[0] <= time <= zone[1]:\n",
    "            tweet_time_dict[(zone[0],zone[1])] = tweet_time_dict.get((zone[0],zone[1]), 0) + 1\n",
    "            \n",
    "print(tweet_time_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[('RT @juliebrowse: Monday looooms ... https://t.co/R3oiMLunhN', '2018/4/15 16:15'), ('RT @swear_trek: https://t.co/EsXMXFfUnk', '2018/4/14 16:51'), ('@deedeesadler Same to you lovely lady', '2018/4/14 16:50'), ('RT @ansonmount: This was something close to my reaction upon hearing that I was cast in @startrekcbs     #StarTrek #StarTrekDiscovery httpsâ€¦', '2018/4/13 16:1'), ('An oldie but a goodie https://t.co/xHJIt4DO7S', '2018/1/24 17:22'), ('@ParkerFilmCo Oh. Thought it was the ship from Lost in Space for a moment. Looks awesome', '2018/1/24 17:22')]\n"
     ]
    }
   ],
   "source": [
    "# find outlier tweets\n",
    "outlier_tweets = []\n",
    "for i in user2:\n",
    "    year = i[1].year\n",
    "    month = i[1].month\n",
    "    day = i[1].day\n",
    "    hour = i[1].hour\n",
    "    minute = i[1].minute\n",
    "    date = str(year) + '/' + str(month) + '/' + str(day) + ' ' + str(hour) + ':' + str(minute)\n",
    "    time = time = hour + float(minute / 60)\n",
    "    if 16 <= time <= 18:\n",
    "        outlier_tweets.append((i[0], date))\n",
    "\n",
    "print(len(outlier_tweets))\n",
    "print(outlier_tweets)\n",
    "\n",
    "# write outlier tweets to a file\n",
    "f = open('outlier_tweets.txt','w')\n",
    "for i in outlier_tweets:\n",
    "    f.write('\\n{}\\n'.format(i))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# travel hit map\n",
    "def getTimeAndLocation(user):\n",
    "    time_location = []\n",
    "    for i in user:\n",
    "        if i[2]:\n",
    "            time_location.append((i[1], i[2]['coordinates']))\n",
    "    return time_location\n",
    "\n",
    "user_time_location = getTimeAndLocation(user2)\n",
    "travel_map = {}\n",
    "heat_map = {}\n",
    "for i in user_time_location:\n",
    "    coordinate = (i[1][1], i[1][0])\n",
    "    year = i[0].year\n",
    "    month = i[0].month\n",
    "    day = i[0].day\n",
    "    date = str(year) + '/' + str(month) + '/' + str(day)\n",
    "    # update the hit map\n",
    "    heat_map[coordinate] = heat_map.get(coordinate, 0) + 1\n",
    "    # update the travel location\n",
    "    travel_location_list = travel_map.get(date, set())\n",
    "    travel_location_list.add(coordinate)\n",
    "    travel_map[date] = travel_location_list\n",
    "\n",
    "heat_map = sorted(heat_map.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-36.38596635, 148.84645611) => 73\n",
      "\n",
      "(-33.75379065, 151.29704833) => 46\n",
      "\n",
      "(-33.6167, 150.817) => 40\n",
      "\n",
      "(-37.0667, 149.9) => 32\n",
      "\n",
      "(-36.3667, 148.833) => 24\n",
      "\n",
      "(-36.93110107, 149.87290142) => 21\n",
      "\n",
      "(-36.9, 149.9) => 20\n",
      "\n",
      "(-33.61459, 150.81334) => 17\n",
      "\n",
      "(-36.9, 149.233) => 14\n",
      "\n",
      "(-34.4333, 148.733) => 14\n",
      "\n",
      "(-36.4167, 150.05) => 13\n",
      "\n",
      "(-33.63857815, 150.79984402) => 13\n",
      "\n",
      "(-33.85678499, 151.21528387) => 11\n",
      "\n",
      "(-33.7, 150.55) => 11\n",
      "\n",
      "(-33.8848, 151.226) => 11\n",
      "\n",
      "(-33.5, 150.38333333) => 10\n",
      "\n",
      "(-37.17861111, 149.98222222) => 10\n",
      "\n",
      "(-33.815171, 151.009996) => 10\n",
      "\n",
      "(-36.2333, 149.133) => 9\n",
      "\n",
      "(-36.50421, 148.83459) => 9\n",
      "\n",
      "(-33.86, 151.211) => 9\n",
      "\n",
      "(-33.63796992, 150.79586677) => 8\n",
      "\n",
      "(-36.407189, 150.0546115) => 8\n",
      "\n",
      "(-33.8833, 151.225) => 8\n",
      "\n",
      "(-36.4167, 148.333) => 8\n",
      "\n",
      "(-33.87111111, 151.21333333) => 8\n",
      "\n",
      "(-37.10338, 149.8801) => 7\n",
      "\n",
      "(-33.608134, 150.7884737) => 7\n",
      "\n",
      "(-33.6054276, 150.8226541) => 7\n",
      "\n",
      "(-33.58625505, 150.85934191) => 6\n",
      "\n",
      "(-33.6, 150.767) => 6\n",
      "\n",
      "(-36.8333, 149.367) => 6\n",
      "\n",
      "(-33.8167, 151.0) => 6\n",
      "\n",
      "(-33.51530863, 150.58197069) => 5\n",
      "\n",
      "(-37.26139167, 150.04932778) => 5\n",
      "\n",
      "(-36.2463268, 149.0776806) => 5\n",
      "\n",
      "(-37.0818, 149.8846) => 4\n",
      "\n",
      "(-33.87769, 151.21668) => 4\n",
      "\n",
      "(-34.438868, 148.717484) => 4\n",
      "\n",
      "(-34.43631, 148.71716) => 4\n",
      "\n",
      "(-33.55372, 150.6670399) => 4\n",
      "\n",
      "(-33.74583507, 150.85359124) => 4\n",
      "\n",
      "(-33.88491, 151.20185) => 4\n",
      "\n",
      "(-33.53911051, 150.42278614) => 3\n",
      "\n",
      "(-37.15, 149.867) => 3\n",
      "\n",
      "(-37.0485, 149.91789) => 3\n",
      "\n",
      "(-37.12645, 149.94584) => 3\n",
      "\n",
      "(-36.6667, 149.833) => 3\n",
      "\n",
      "(-33.60973, 150.8074) => 3\n",
      "\n",
      "(-34.78226, 149.26786) => 3\n",
      "\n",
      "(-36.3768929, 148.57796894) => 3\n",
      "\n",
      "(-33.87078743, 151.21105825) => 3\n",
      "\n",
      "(-33.8403759, 151.1826651) => 3\n",
      "\n",
      "(-34.9123, 143.332) => 2\n",
      "\n",
      "(-36.89478528, 149.89486316) => 2\n",
      "\n",
      "(-33.60805, 150.81902) => 2\n",
      "\n",
      "(-33.86074034, 151.21069483) => 2\n",
      "\n",
      "(-33.5667, 150.833) => 2\n",
      "\n",
      "(-33.55555304, 150.79724127) => 2\n",
      "\n",
      "(-34.3167, 148.3) => 2\n",
      "\n",
      "(-33.8667, 151.225) => 2\n",
      "\n",
      "(-36.5167, 149.283) => 2\n",
      "\n",
      "(-35.95, 149.15) => 2\n",
      "\n",
      "(-35.8205688, 148.36633106) => 2\n",
      "\n",
      "(-36.41057498, 148.40467789) => 2\n",
      "\n",
      "(-33.5893, 150.711) => 2\n",
      "\n",
      "(-33.4167, 150.783) => 2\n",
      "\n",
      "(-33.84828264, 151.21210854) => 2\n",
      "\n",
      "(-33.882332, 151.2057286) => 2\n",
      "\n",
      "(-33.88410698, 151.21043953) => 2\n",
      "\n",
      "(-33.87947799, 151.21528034) => 2\n",
      "\n",
      "(-33.89334, 151.20461) => 2\n",
      "\n",
      "(-33.87387709, 151.20651103) => 2\n",
      "\n",
      "(-33.89414, 151.12931) => 2\n",
      "\n",
      "(-33.85666667, 151.215) => 2\n",
      "\n",
      "(-33.70322602, 151.27297028) => 2\n",
      "\n",
      "(-36.89413993, 149.91848946) => 2\n",
      "\n",
      "(-33.87191, 151.2068651) => 1\n",
      "\n",
      "(-37.10270646, 149.95316355) => 1\n",
      "\n",
      "(-33.60904727, 150.6965296) => 1\n",
      "\n",
      "(-33.6106, 150.791) => 1\n",
      "\n",
      "(-33.8833, 151.1) => 1\n",
      "\n",
      "(-33.0333, 149.417) => 1\n",
      "\n",
      "(-33.57042832, 150.85292041) => 1\n",
      "\n",
      "(-34.05538794, 150.69413303) => 1\n",
      "\n",
      "(-34.0492532, 151.0470444) => 1\n",
      "\n",
      "(-35.9167, 150.083) => 1\n",
      "\n",
      "(-35.91096, 150.0802799) => 1\n",
      "\n",
      "(-33.87290529, 151.22499908) => 1\n",
      "\n",
      "(-33.86919734, 150.93484285) => 1\n",
      "\n",
      "(-33.60983, 150.75437) => 1\n",
      "\n",
      "(-33.5528534, 150.82913568) => 1\n",
      "\n",
      "(-33.75, 150.7) => 1\n",
      "\n",
      "(-33.55, 150.66666667) => 1\n",
      "\n",
      "(-34.75, 149.717) => 1\n",
      "\n",
      "(-37.07189878, 149.90994667) => 1\n",
      "\n",
      "(-36.25026497, 149.07839868) => 1\n",
      "\n",
      "(-36.4167, 148.633) => 1\n",
      "\n",
      "(-36.41472508, 148.61656186) => 1\n",
      "\n",
      "(-33.53593112, 150.87382182) => 1\n",
      "\n",
      "(-33.61040821, 150.82002856) => 1\n",
      "\n",
      "(-35.25811083, 149.14203169) => 1\n",
      "\n",
      "(-33.87501, 150.6888899) => 1\n",
      "\n",
      "(-32.8152, 151.4346) => 1\n",
      "\n",
      "(-33.84371259, 151.2083274) => 1\n",
      "\n",
      "(-33.64685425, 150.85893992) => 1\n",
      "\n",
      "(-33.7167, 150.867) => 1\n",
      "\n",
      "(-33.8718, 151.09433056) => 1\n",
      "\n",
      "(-33.81770833, 151.00556944) => 1\n",
      "\n",
      "(-33.87431167, 151.21159825) => 1\n",
      "\n",
      "(-33.60988166, 150.81609736) => 1\n",
      "\n",
      "(-33.75, 150.667) => 1\n",
      "\n",
      "(-33.615, 150.828) => 1\n",
      "\n",
      "(-33.84197805, 151.18059962) => 1\n",
      "\n",
      "(-33.8868, 151.2024) => 1\n",
      "\n",
      "(-36.89419875, 149.91751069) => 1\n",
      "\n",
      "(-36.89515365, 149.92424477) => 1\n",
      "\n",
      "(-35.28013993, 149.11965634) => 1\n",
      "\n",
      "-----------\n",
      "2018/5/7, {(-33.51530863, 150.58197069), (-34.9123, 143.332)}\n",
      "\n",
      "\n",
      "2018/5/3, {(-33.58625505, 150.85934191)}\n",
      "\n",
      "\n",
      "2018/5/1, {(-33.61459, 150.81334), (-33.51530863, 150.58197069), (-33.53911051, 150.42278614), (-33.5, 150.38333333)}\n",
      "\n",
      "\n",
      "2018/4/30, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/4/29, {(-33.6167, 150.817), (-33.51530863, 150.58197069)}\n",
      "\n",
      "\n",
      "2018/4/28, {(-36.93110107, 149.87290142), (-36.9, 149.9), (-37.0818, 149.8846), (-37.0667, 149.9)}\n",
      "\n",
      "\n",
      "2018/4/27, {(-37.0667, 149.9), (-37.10338, 149.8801), (-36.89478528, 149.89486316), (-36.9, 149.9), (-33.608134, 150.7884737), (-33.60805, 150.81902)}\n",
      "\n",
      "\n",
      "2018/4/26, {(-33.87191, 151.2068651), (-33.86074034, 151.21069483), (-33.85678499, 151.21528387)}\n",
      "\n",
      "\n",
      "2018/4/25, {(-36.9, 149.9)}\n",
      "\n",
      "\n",
      "2018/4/24, {(-37.15, 149.867), (-37.0485, 149.91789), (-37.0667, 149.9), (-37.10270646, 149.95316355), (-33.6, 150.767), (-33.5667, 150.833), (-33.61459, 150.81334), (-33.60904727, 150.6965296), (-37.26139167, 150.04932778)}\n",
      "\n",
      "\n",
      "2018/4/23, {(-33.7, 150.55)}\n",
      "\n",
      "\n",
      "2018/4/22, {(-33.63796992, 150.79586677), (-33.608134, 150.7884737), (-33.6167, 150.817), (-33.8833, 151.1), (-33.6106, 150.791)}\n",
      "\n",
      "\n",
      "2018/4/20, {(-33.608134, 150.7884737)}\n",
      "\n",
      "\n",
      "2018/4/18, {(-37.17861111, 149.98222222), (-37.12645, 149.94584), (-37.0667, 149.9), (-36.9, 149.9), (-37.26139167, 150.04932778)}\n",
      "\n",
      "\n",
      "2018/4/16, {(-36.407189, 150.0546115), (-33.7, 150.55), (-36.4167, 150.05)}\n",
      "\n",
      "\n",
      "2018/4/15, {(-36.407189, 150.0546115), (-36.4167, 150.05)}\n",
      "\n",
      "\n",
      "2018/4/14, {(-36.4167, 150.05), (-36.407189, 150.0546115), (-37.17861111, 149.98222222)}\n",
      "\n",
      "\n",
      "2018/4/12, {(-33.6167, 150.817)}\n",
      "\n",
      "\n",
      "2018/4/11, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/4/10, {(-36.9, 149.233), (-36.8333, 149.367), (-36.6667, 149.833)}\n",
      "\n",
      "\n",
      "2018/4/7, {(-36.93110107, 149.87290142), (-36.9, 149.9), (-33.55555304, 150.79724127)}\n",
      "\n",
      "\n",
      "2018/4/6, {(-34.9123, 143.332), (-36.6667, 149.833), (-36.9, 149.9), (-33.63796992, 150.79586677), (-33.6167, 150.817), (-33.61459, 150.81334), (-33.6054276, 150.8226541), (-33.60973, 150.8074), (-33.0333, 149.417)}\n",
      "\n",
      "\n",
      "2018/4/5, {(-36.89478528, 149.89486316)}\n",
      "\n",
      "\n",
      "2018/4/1, {(-33.6167, 150.817), (-33.75379065, 151.29704833), (-33.63796992, 150.79586677), (-33.60973, 150.8074)}\n",
      "\n",
      "\n",
      "2018/3/31, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/3/30, {(-33.60973, 150.8074)}\n",
      "\n",
      "\n",
      "2018/3/29, {(-33.75379065, 151.29704833)}\n",
      "\n",
      "\n",
      "2018/3/28, {(-33.6167, 150.817), (-33.75379065, 151.29704833)}\n",
      "\n",
      "\n",
      "2018/3/23, {(-33.6167, 150.817), (-33.5667, 150.833), (-33.61459, 150.81334), (-33.87769, 151.21668), (-33.8833, 151.225), (-33.57042832, 150.85292041), (-33.63857815, 150.79984402)}\n",
      "\n",
      "\n",
      "2018/3/22, {(-34.0492532, 151.0470444), (-34.05538794, 150.69413303)}\n",
      "\n",
      "\n",
      "2018/3/20, {(-33.6, 150.767), (-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/3/15, {(-35.9167, 150.083), (-36.9, 149.233), (-36.2333, 149.133), (-33.6167, 150.817)}\n",
      "\n",
      "\n",
      "2018/3/5, {(-34.438868, 148.717484), (-34.43631, 148.71716)}\n",
      "\n",
      "\n",
      "2018/3/2, {(-34.3167, 148.3), (-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/2/28, {(-35.91096, 150.0802799)}\n",
      "\n",
      "\n",
      "2018/2/25, {(-33.86919734, 150.93484285), (-33.87290529, 151.22499908), (-33.8667, 151.225), (-33.8833, 151.225), (-33.87769, 151.21668)}\n",
      "\n",
      "\n",
      "2018/2/24, {(-33.75379065, 151.29704833)}\n",
      "\n",
      "\n",
      "2018/2/22, {(-34.4333, 148.733), (-34.78226, 149.26786)}\n",
      "\n",
      "\n",
      "2018/2/19, {(-33.6167, 150.817)}\n",
      "\n",
      "\n",
      "2018/2/18, {(-33.63857815, 150.79984402), (-33.6167, 150.817), (-33.60983, 150.75437)}\n",
      "\n",
      "\n",
      "2018/2/15, {(-33.61459, 150.81334), (-33.75379065, 151.29704833)}\n",
      "\n",
      "\n",
      "2018/2/14, {(-33.5528534, 150.82913568)}\n",
      "\n",
      "\n",
      "2018/2/11, {(-36.2333, 149.133), (-33.6167, 150.817), (-36.3667, 148.833)}\n",
      "\n",
      "\n",
      "2018/2/10, {(-34.75, 149.717), (-36.2333, 149.133), (-36.5167, 149.283), (-33.75, 150.7), (-36.3667, 148.833), (-33.55, 150.66666667), (-33.6167, 150.817)}\n",
      "\n",
      "\n",
      "2018/2/2, {(-36.3667, 148.833), (-35.95, 149.15)}\n",
      "\n",
      "\n",
      "2018/2/1, {(-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2018/1/27, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2018/1/25, {(-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2018/1/21, {(-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2018/1/20, {(-37.0667, 149.9), (-36.38596635, 148.84645611), (-36.3667, 148.833), (-37.07189878, 149.90994667)}\n",
      "\n",
      "\n",
      "2018/1/19, {(-35.8205688, 148.36633106), (-36.2463268, 149.0776806), (-36.2333, 149.133), (-36.25026497, 149.07839868), (-36.38596635, 148.84645611), (-36.3667, 148.833), (-36.4167, 148.633), (-36.4167, 148.333), (-36.41472508, 148.61656186)}\n",
      "\n",
      "\n",
      "2018/1/14, {(-36.3768929, 148.57796894), (-36.4167, 148.333), (-36.41057498, 148.40467789), (-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2018/1/12, {(-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2018/1/11, {(-33.63857815, 150.79984402), (-36.38596635, 148.84645611), (-33.53593112, 150.87382182)}\n",
      "\n",
      "\n",
      "2018/1/10, {(-33.61040821, 150.82002856), (-33.6167, 150.817), (-33.63857815, 150.79984402), (-33.7, 150.55)}\n",
      "\n",
      "\n",
      "2018/1/3, {(-36.38596635, 148.84645611), (-36.3667, 148.833)}\n",
      "\n",
      "\n",
      "2018/1/2, {(-36.50421, 148.83459), (-36.38596635, 148.84645611)}\n",
      "\n",
      "\n",
      "2017/12/31, {(-36.38596635, 148.84645611), (-36.3667, 148.833)}\n",
      "\n",
      "\n",
      "2017/12/30, {(-36.3667, 148.833), (-36.50421, 148.83459), (-35.25811083, 149.14203169)}\n",
      "\n",
      "\n",
      "2017/12/29, {(-33.87501, 150.6888899)}\n",
      "\n",
      "\n",
      "2017/12/27, {(-32.8152, 151.4346)}\n",
      "\n",
      "\n",
      "2017/12/24, {(-33.5893, 150.711), (-33.4167, 150.783)}\n",
      "\n",
      "\n",
      "2017/12/23, {(-33.61459, 150.81334), (-33.6167, 150.817), (-33.4167, 150.783), (-33.8167, 151.0), (-33.815171, 151.009996), (-33.84828264, 151.21210854)}\n",
      "\n",
      "\n",
      "2017/12/22, {(-33.55372, 150.6670399), (-33.74583507, 150.85359124), (-33.87078743, 151.21105825), (-33.88491, 151.20185), (-33.882332, 151.2057286)}\n",
      "\n",
      "\n",
      "2017/12/21, {(-33.84371259, 151.2083274)}\n",
      "\n",
      "\n",
      "2017/12/17, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2017/12/10, {(-33.61459, 150.81334)}\n",
      "\n",
      "\n",
      "2017/12/3, {(-33.87947799, 151.21528034), (-33.55372, 150.6670399), (-33.60988166, 150.81609736), (-33.75, 150.667), (-33.63857815, 150.79984402), (-33.6167, 150.817), (-33.64685425, 150.85893992), (-33.86074034, 151.21069483), (-33.86, 151.211), (-33.7167, 150.867), (-33.8718, 151.09433056), (-33.88410698, 151.21043953), (-33.81770833, 151.00556944), (-33.87111111, 151.21333333), (-33.87431167, 151.21159825), (-33.8848, 151.226), (-33.8833, 151.225)}\n",
      "\n",
      "\n",
      "2017/11/26, {(-33.87111111, 151.21333333)}\n",
      "\n",
      "\n",
      "2017/11/22, {(-33.58625505, 150.85934191), (-33.87111111, 151.21333333), (-33.87387709, 151.20651103), (-33.89334, 151.20461), (-33.87078743, 151.21105825), (-33.8833, 151.225), (-33.87947799, 151.21528034)}\n",
      "\n",
      "\n",
      "2017/11/18, {(-33.55372, 150.6670399)}\n",
      "\n",
      "\n",
      "2017/11/15, {(-33.615, 150.828), (-33.8868, 151.2024), (-33.8848, 151.226), (-33.87387709, 151.20651103), (-33.8403759, 151.1826651), (-33.88410698, 151.21043953), (-33.89414, 151.12931), (-33.84197805, 151.18059962), (-33.8833, 151.225), (-33.89334, 151.20461), (-33.85666667, 151.215), (-33.70322602, 151.27297028)}\n",
      "\n",
      "\n",
      "2017/11/11, {(-37.0667, 149.9), (-35.28013993, 149.11965634), (-36.9, 149.9), (-36.89515365, 149.92424477), (-36.89413993, 149.91848946), (-36.89419875, 149.91751069)}\n",
      "\n",
      "\n",
      "2017/11/10, {(-37.0667, 149.9)}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in heat_map:\n",
    "    print('{} => {}\\n'.format(i[0], i[1]))\n",
    "\n",
    "print('-----------')\n",
    "\n",
    "for k,v in travel_map.items():\n",
    "    print('{}, {}\\n\\n'.format(k,v))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
